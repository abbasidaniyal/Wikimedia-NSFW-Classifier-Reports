{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the percentage of NSFW and SFW content in a video\n",
    "\n",
    "For this, I take inspiration from the libraries mentioned in the Phabricator task description: https://phabricator.wikimedia.org/T264050 \n",
    "\n",
    "I use the **PySceneDetect library**.\n",
    "\n",
    "I use the following to extract frame with content-aware detection feature of PySceneDetect (which reduces the number of extracted frames by a huge margin, compared to a generic video frame extractor, and hence helps with faster classification).\n",
    "\n",
    "<code> scenedetect --input video1.mp4 detect-content list-scenes save-images </code>\n",
    "\n",
    "After this, I loop through the extracted frames to determine the NSFW and SFW percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras.preprocessing import image\n",
    "from IPython.display import Image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\Harshinee Sriram\\OneDrive\\Desktop\\Wikimedia\\NSFW classifier\\Jupyter notebooks')\n",
    "try_this_model = models.load_model('model_MobileNet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a Hentai  video\n",
    "\n",
    "Original video link: https://www.youtube.com/watch?v=ZWc8taUoO6M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This video has 3% NSFW content.\n",
      "This video has 97% SFW content.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\Harshinee Sriram\\OneDrive\\Desktop\\Wikimedia\\NSFW classifier\\Video Clips\\Frames')\n",
    "\n",
    "amount_of_nsfw = 0\n",
    "amount_of_sfw = 0\n",
    "for test_img in os.listdir():\n",
    "    #display(Image(filename=test_img, height=100, width=100))\n",
    "    #display(Image(test_img))\n",
    "    img = image.load_img(test_img, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "    img = preprocess_input(img)\n",
    "    yhat = try_this_model.predict(img)\n",
    "    if(np.argmax(yhat) == 0):\n",
    "        amount_of_nsfw = amount_of_nsfw + 1\n",
    "    else:\n",
    "        amount_of_sfw = amount_of_sfw + 1  \n",
    "    #print(yhat)\n",
    "    \n",
    "percentage_of_nsfw = ((amount_of_nsfw)/len(os.listdir()))*100\n",
    "percentage_of_sfw = ((amount_of_sfw)/len(os.listdir()))*100\n",
    "\n",
    "print(\"This video has \" + str(int(math.ceil(percentage_of_nsfw))) + \"% NSFW content.\")\n",
    "print(\"This video has \" + str(100 - int(math.ceil(percentage_of_nsfw))) + \"% SFW content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing an animal documentary short film\n",
    "\n",
    "Original video link: https://www.youtube.com/watch?v=B3OjfK0t1XM&t=22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This video has 0% NSFW content.\n",
      "This video has 100% SFW content.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\Harshinee Sriram\\OneDrive\\Desktop\\Wikimedia\\NSFW classifier\\Video Clips\\Frames')\n",
    "\n",
    "amount_of_nsfw = 0\n",
    "amount_of_sfw = 0\n",
    "for test_img in os.listdir():\n",
    "    #display(Image(filename=test_img, height=100, width=100))\n",
    "    #display(Image(test_img))\n",
    "    img = image.load_img(test_img, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "    img = preprocess_input(img)\n",
    "    yhat = try_this_model.predict(img)\n",
    "    if(np.argmax(yhat) == 0):\n",
    "        amount_of_nsfw = amount_of_nsfw + 1\n",
    "    else:\n",
    "        amount_of_sfw = amount_of_sfw + 1  \n",
    "    #print(yhat)\n",
    "    \n",
    "percentage_of_nsfw = ((amount_of_nsfw)/len(os.listdir()))*100\n",
    "percentage_of_sfw = ((amount_of_sfw)/len(os.listdir()))*100\n",
    "\n",
    "print(\"This video has \" + str(int(math.ceil(percentage_of_nsfw))) + \"% NSFW content.\")\n",
    "print(\"This video has \" + str(100 - int(math.ceil(percentage_of_nsfw))) + \"% SFW content.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

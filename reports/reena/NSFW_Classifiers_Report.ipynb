{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSFW Classifiers Report\n",
    "### Microtask - T264056: Comparison of Existing NSFW Classifiers\n",
    "##### Existing Models - \n",
    "\n",
    "<br> * Most of the existing classifiers are focusing on transfer learning which makes it feasible to achieve higher accuracy and performance efficiently. The algorithms introduced within the ILSVRC ImageNet Competition are getting more accurate day-by-day. Fine tuning these ConvNets leads to massive improvements in the accuracies. Here is the lising of various research papers, articles and blogs.\n",
    "\n",
    "<br> * Using transfer learning to classify pornographic Images \n",
    "<br>source - https://ieeexplore.ieee.org/abstract/document/9044231 (2020)\n",
    "Dataset - NPDI Pornography dataset\n",
    "Accuracy - 98.01%\n",
    "<br> Comparision of proposed Alex Net, VGG-16 Net and Xception Net by fine tuning first two layers only.\n",
    "\n",
    "| Model | Precision | Recall  | Accuracy| Remarks\n",
    "|-------|--------|---------|-------|-------\n",
    "|Custom | 0.62| 1.00|0.50 | Underfit\n",
    "| VNet- Pretrained | 0.90 | 0.98 | 0.91 | Slightly Biased towards Negative\n",
    "| **VNet – 2 layers**| **0.99** |  **0.98** | **0.98** |  **Best Model**\n",
    "| ANet – 2 layers | 0.99|  0.93 | 0.96 |Slightly Biased towards Positive \n",
    "| XNet – Pretrained | 0.61 | 0.35 | 0.49 | Random Model\n",
    "\n",
    "<br> Authors Conclusion: we are using the ConvNet as a general feature extractor (the first seven layers) and as a classifier (the last layer). This fine-tune training method lets the network train faster with less numbers of coaching data than the complete method because it has less parameters to adapt (those of the last layer only). \n",
    "\n",
    "<br> * AlexNet, GoogleNet and Fusion of AlexNet and GoogleNet \n",
    "<br> Source -  https://arxiv.org/pdf/1511.08899.pdf\n",
    "<br> Accuracy - 94.1\n",
    "<br> Binary classifier - Benign or porn, training just the last layer of the model with NPDI dataset.\n",
    " \n",
    "| Model | Accuracy|\n",
    "|---------|---------|\n",
    "|ANet |  92.01\n",
    "|GNet | 93.7\n",
    "|AGNet| 93.8\n",
    "|**AGbNet(score 'fusion' is larger of ANet and GNet)** | **94.1**\n",
    "\n",
    "<br>* NSFW detection using MobileNetV2 \n",
    "<br>Source - https://github.com/lakshaychhabra/NSFW-Detection-DL, https://github.com/GantMan/nsfw_model\n",
    "<br>Accuracy - 93.5%\n",
    "<br>Dataset - Alexander Kim's dataset\n",
    "<br>Pros - Fast and less parameters to train. \n",
    "<img src=\"./nsfw_confusion_inceptionv3.png\"/>\n",
    "\n",
    "<br>* ConvNets on COVID-19 image data collection to detect COVID-19 and non-COVID pneumonia\n",
    "(https://www.nature.com/articles/s41598-020-70479-z)\n",
    "<br>Conclusion - Out of 16 different architectures of CNN - AlexNet, DenseNet-121, DenseNet-161, DenseNet-169, DenseNet-201, Inception v4, ResNet-101, ResNet-152, ResNet-18, ResNet-34, ResNet-50, SqueezeNet-1.0, SqueezeNet-1.1, VGG-13, VGG-16, VGG-19, ResNet proofs to be an efficient model by achieving high accuracy in limited time for training. \n",
    "\n",
    "<br>* Yahoo's Caffe deep neural network model\n",
    "Source - https://github.com/yahoo/open_nsfw\n",
    "<br> Comparision of MS_CTC, SqueezeNet, VGG, GoogLeNet, ResNet-50, ResNet-50-thin (https://yahooeng.tumblr.com/post/151148689421/open-sourcing-a-deep-learning-solution-for)\n",
    "<img src=\"./yahoo_comparision.jpg\"/>\n",
    "<br>Chose the thin ResNet 50 model, since it provides good tradeoff in terms of accuracy, and the model is lightweight in terms of runtime (takes < 0.5 sec on CPU) and memory (~23 MB).\n",
    "\n",
    "<br>* There are few other approaches like Skin based or manually extracted feature models for detecting nudity - Loop-hole - High False positive ratio in detection due to misjudgement. \n",
    " <br >Bag-of-Visual-Word approach - Loop-hole - Incorrect mapping of low-level-features to a feature vector.\n",
    "<br>  Local Receptive Field-Extreme Learning Machine (LRF-ELM) to detect nudity in videos - Pros - lowcost, very less training time, No fine tuning of the weights.\n",
    "<br> Loop-hole - Comparitively low accuracy.\n",
    "\n",
    "| Accuracy| Training time|\n",
    "|------------------------------|-------------------------------|\n",
    "|<img src = \"./erm_acc.png\" /> | <img src = \"./erm_time.png\" /> |\n",
    "\n",
    "<br>* Since transfer learning has been showing high improvement lately. Here is a small comparision of various Convolutional nets and their accuracy.\n",
    "\n",
    "Source - https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d\n",
    "<img src=\"./10_cnn_comparision.png\" />\n",
    "\n",
    "##### Popular Convolutional nets\n",
    "<br>* Comparision of winners of ImageNet Large Scale Visual Recognition Challenge(ILSVRC) competition 2010 - 2017\n",
    "Source - https://www.kaggle.com/getting-started/149448\n",
    "<img src=\"./ILSVRC_winners_error.png\">\n",
    "\n",
    "<br>* Comparision of popular convolutional networks and their Top-5 error rate on ImageNet dataset.\n",
    "(https://machinelearningknowledge.ai/popular-image-classification-models-in-imagenet-challenge-ilsvrc-competition-history/#Conclusion, https://arxiv.org/ftp/arxiv/papers/1901/1901.06032.pdf)\n",
    "\n",
    "Model | Top-5 error rate |Parameters| Remarks\n",
    "----|-----|-----|------\n",
    "PNASNet-5(Winner 2018) | 3.8% | |Reinforcement learning, 5 times more efficient and 8 times faster\n",
    "SENet(Winner 2017) | 2.251% | 27.5| Models interdependencies between feature-maps, squeezes global spatial information into a channel descriptor. \n",
    "ResNeXt-10(Runners Up 2016) | 4.1% | 68.1M|Cardinality, Homogeneous topology, Grouped convolution, Less number of parameters because of uniformity in topology\n",
    "ResNet (Winner 2015) | 3.57% |25.6M| No vanishing gradient problem because of information being preserved in residuals\n",
    "VGG-16(Runners-Up 2014 | 7.3% | 138M| Uses 3*3 kernel-sizedd filters unlike large-sized filters in AlexNet,ZFNet. Very slow to train, and the network weights, higher memory requirement.\n",
    "Inception- V1(GoogleNet) (Winner 2014) | 6.67% | 4M| Deep network with 1*1 convolutional and ReLU for reducing dimensions and number of operations.\n",
    "ZFNet (Winner 2013) | 11.2% |60M| Deep network with 7*7 sized filters but high computation cost. \n",
    "AlexNet (Winner 2012) | 15.2% |60M| Deeper and wider than the LeNet, Uses Relu, dropout and overlap Pooling, Known as the Pioneer of the convolutional network, Use of overlapping pooling\n",
    " \n",
    " <br>* Comparison of performance of various classification models trained on ImageNet dataset alongwith their pre-trained weights. \n",
    " source - https://github.com/qubvel/classification_models, https://github.com/tensorflow/models/blob/master/research/slim/README.md#pre-trained-models\n",
    "<br> Comparison of top accurate models with their training time\n",
    " \n",
    " \n",
    " Model\t|Acc@1\t|Acc@5\t|Time|\tSource\n",
    " --|---|---|---|---\n",
    " nasnetlarge\t|82.12|\t95.72\t|116.53|\tkeras\n",
    " senet154\t|81.06\t|95.24\t|137.36|\tpytorch\n",
    " inceptionresnetv2|\t80.03\t|94.89\t|54.77\t|keras\n",
    "seresnext101|\t79.88\t|94.87|\t62.80\t|pytorch\n",
    "seresnext50\t|78.74\t|94.30\t|38.29\t|pytorch\n",
    "xception\t|78.87\t|94.20\t|42.18\t|keras\n",
    "seresnet152\t|78.34\t|94.08\t|47.88\t|pytorch\n",
    "seresnet101\t|77.92\t|94.00\t|32.55\t|pytorch\n",
    "resnext101\t|78.48\t|94.00\t|60.07\t|keras\n",
    "resnext50\t|77.36\t|93.48\t|37.57\t|keras\n",
    "densenet201\t|77.13\t|93.43\t|42.40\t|keras\n",
    "\n",
    "<br>Conclusion -  NASNET-Large proofs to be best in terms of accuracy but with high training time, whereas InceptionResNetV2 performs good in terms of accuracy and time both. \n",
    "\n",
    "<br>* Morever, I would also like to reflect on uncertain definition of NSFW depending on different situations. I would like to construct a model where we calculate probabilities of different categories and build a decision tree on top of it to declare a binary decision.  \n",
    "\n",
    "<br>* Incorporating decision tree on top of convolutional model probabilities to obtain binary decisions\n",
    "Source - https://ieeexplore.ieee.org/document/9206701\n",
    "\n",
    "Model| Layers |Train| Validation\n",
    "----|----|----|-----\n",
    "ResNet|18 |99.5% |97.6%\n",
    "|34 |99.4% |97.7%\n",
    "|50 |98.8% |97.4%\n",
    "|101 |98.7% |97.3%\n",
    "|152 |99.2% |97.7%\n",
    "Wide ResNet|50 |97.6% |97.2%\n",
    "|101| 99.3% |97.4%\n",
    "ResNext|50|99.2%|98.1%\n",
    "|101 |99.4% |97.8%\n",
    "DenseNet|121 |99.4% |98.5%\n",
    "|161 |99.5% |98.3%\n",
    "|169 |99.6% |98.5%\n",
    "|201 |98.6% |98.2%\n",
    "\n",
    "<br>A binary decision tree is trained for each feature separately and a final tree is used to combine all other trees. The best configuration of hyperparameters found includes a Densenet-121 with batch size of 128 trained with an SGD optimizer and a learning rate of 2^-8. This configuration achieved 99.2% in the validation set as well as in the test set.\n",
    "\n",
    "Dataset |Model |Raw |Optimized\n",
    "---|----|----|---\n",
    "PEDA 376K| Proposed |99.1 ± 0.1 |\n",
    "|Amazon  |96.9 ± 0.0| 97.9 ± 0.0\n",
    "|Clarifai | 96.4 ± 0.0 |97.4 ± 0.0\n",
    "|Google | 96.5 ± 0.1 |96.7 ± 0.2\n",
    "|Microsoft | 93.6 ± 0.1 |95.8 ± 0.1\n",
    "|Yahoo | 95.1 ± 0.1 |96.1 ± 0.0\n",
    "RedLight |Proposed |95.2 ± 0.3| 95.6 ± 0.3\n",
    "|Amazon | 95.3 ± 0.3| 96.5 ± 0.3\n",
    "|Clarifai | 92.6 ± 0.3| 93.0 ± 0.1\n",
    "|Google | 94.7 ± 0.2 |95.1 ± 0.2\n",
    "|Microsoft | 94.4 ± 0.3 |95.5 ± 0.2\n",
    "|Yahoo | 94.2 ± 0.3 |94.2 ± 0.3\n",
    "\n",
    "> Listing of various methods for pornography detection from videos\n",
    "\n",
    "<br>* Deep One-Class with Attention for Pornography (DOCAPorn)\n",
    "(https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9141172)\n",
    "<br> Accuracy: 98.419% on owm dataset, 95.632% on NPDI dataset\n",
    "Approach: Deep One-Class with Attention for Pornography (DOCAPorn) that recognizes the pornographic\n",
    "images through the one-class classification model based on neural networks and introduces the visual\n",
    "attention mechanism to enhance the performance of recognition.\n",
    " <br> The Scale Constraint Pooling (SCP) that converts the inputs of different dimensions into outputs of the same dimension.\n",
    " <br>  Preprocessing for Compressing and Reconstructing (PreCR), a pre-processing approach that reduces the subtle perturbation through compressing the images and then reconstructs the purified image for recognition.\n",
    " <img src=\"DOCAPorn_comparision.png\"/>\n",
    "Conclusion:  The one-class classification based on deep learning can avoid the problem of infinite types in the negative samples due to the fact that it only recognizes the target object. Thus, avoiding the problem of inadequate negative samples.\n",
    "<br>  Moreover, since the proposed DOCAPorn pays more attention to learn the representation of the target class, it reduces the impact of uncertainty in classification tasks.\n",
    "\n",
    "<br>* Video pornography detection using deep learning techniques and motion information  (https://www.researchgate.net/publication/311551085_Video_pornography_detection_through_deep_learning_techniques_and_motion_information)\n",
    "<br>Accuracy : 97.9%\n",
    "<br>Approach : A novel method for classifying pornographic videos, using con\u0002volutional neural networks along with static and motion informa\u0002tion;\n",
    "<br> A new technique for exploring the motion information contained in\n",
    "the MPEG motion vectors [26];\n",
    "<br> A study of different forms of combining the static and motion\n",
    "information extracted from questioned videos.\n",
    "<img src=\"motion_comparision.png\"/>\n",
    "<br>Conclusion :The association of\n",
    "Deep Learning with the combined use of static and motion informa\u0002tion, considerably improves pornography detection. Further,  The LSTM architecture could be\n",
    "used to process the CNN extracted features, using the proposed\n",
    "methods in this work, from a fixed number of frames, improving the\n",
    "real-time classification.\n",
    "\n",
    "<br>* Violation Detection of Live Video Based on Deep Learning\n",
    "<br>Approach - ResNet-50\n",
    "<br>Accuracy - 96.18%\n",
    "<img src=\"ResNet_comparision.png\"/>\n",
    "<br>Conclusion - The addition of residual network modules will increase the network’s generalization level and reduce the complex calculation process of deep networks. ResNet-50 is a relatively mature network\n",
    "structure. According to the experimental results, it can be seen that the network model performs relatively well for various indicators of video detection. However, variable kernel size will result in measurable improvements. \n",
    "\n",
    "<br>* 3D CNNs for Pornography Detection in Videos \n",
    "(https://arxiv.org/pdf/1810.10519.pdf )\n",
    "\n",
    "Approach | Accuracy \n",
    "-----|------\n",
    "VGG-C3D + Linear SVM |  95.1 ± 1.7\n",
    "ResNet R(2+1)D CNN + Softmax |  91.8 ± 2.1\n",
    "\n",
    "<br>These model had been pre-trained on Kinetics dataset. A transfer learning technique was applied to fine-tune the model on the Pornography-800 dataset. \n",
    "<br>Conclusion - These spatiotemporal CNNs proof to be competitive with other CNN-based approachesobserved, reaching an accuracy of 95.1%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microtask - T264938: Comparison of Existing NSFW Datasets\n",
    "###### List of major freely available NSFW datasets.\n",
    "<br> * Pornographic and Explicit dataset (PEDA) 376K (https://ieeexplore.ieee.org/document/9206701)\n",
    "<br> *Pornographic images contain* - (a) depicts a sexual act (regardless of clothing);\n",
    "<br> (b) contains individuals showing a sexual organ, buttocks\n",
    "or female breast.\n",
    "<br> *Non-pornographic images contain* - animals, arts, foods, sports, places, memes, nature, objects, vehicles and people in ordinary situations. I\n",
    "<br>Every image is annotated using the objective definition of pornography.\n",
    "   \n",
    " >  Data Distribution \n",
    "    \n",
    "| Class |  All | Train (95%) | Val. (2.5%) | Test (2.5%)|\n",
    "|-------|------|-------------|-------------|------------|\n",
    "    | Pornography | 150,940 | 141,540 | 4,700 | 4,700|\n",
    "    |Non-pornography |225,094 |215,694 |4,700 |4,700|\n",
    "    |Total| 376,034 | 357,234 | 9,400 | 9,400|\n",
    "    \n",
    "<br> * RedLight\n",
    " <br> A filtered set consists of 25, 616 images (10, 223 pornographic and 15, 393 non-pornographic) after removing duplicated and unreadable images. The entire dataset is split into six partitions in order to perform the same amount of experiments with a distinct combination of train and test sets.\n",
    "This dataset was collected by the Digital Forensics and Cyber Security Center at the University of Rhode Island in 2010 to assist in the development of the RedLight pornography scanner.\n",
    "<br>\n",
    "<br> * Evgeny Bazarov's NSFW data source URLs\n",
    "   <br> Source - https://github.com/EBazarov/nsfw_data_source_urls \n",
    "    <br> This dataset consists of list of URLS of \n",
    "  > 159 different categories\n",
    "             <br> 1589331 URLs\n",
    "             \n",
    " Almost ~500 GB data and ~1300000 NSFW images. The entire dataset contains URLS from reddit.<br>\n",
    " By scraping the data using APIs, we obtain labelled data corresponding to their respective folders\n",
    "\n",
    "<br> * Alexander Kim's datset\n",
    "    <br> Source - https://github.com/alex000kim/nsfw_data_scraper\n",
    "    <br> A dataset categorized into 5 categories\n",
    "  >  drawings -  527kB\n",
    "      <br>   hentai - 157 MB\n",
    "       <br>  neutral - 1.28MB\n",
    "       <br>  porn - 3.18MB\n",
    "      <br>   sexy - 521MB\n",
    "<img sec = \"../confusion_matrix_alex.png\">\n",
    "\n",
    "<br> * RAyraegah's dataset containing NSFW images of asian and japanese content extracted using NSFW data scrapper script\n",
    "<br> source - https://github.com/Rayraegah/nsfw_japan\n",
    "\n",
    "<br> * NPDI pornography database https://sites.google.com/site/ pornographydatabase\n",
    "<br> 80 hours of 400 pornographic videos and 400 non-pornographic videos\n",
    "\n",
    "| Class | Videos| Hours | Shots per video|\n",
    "|--|--|--|--|\n",
    "| Porn | 400 | 57| 15.6|\n",
    "    | Non-Porn (easy) | 200 |  11.5 | 33.8|\n",
    "    | Non-Porn (difficult} | 200 | 8.5 | 17.5|\n",
    "    \n",
    "<br> * Pornography-2k dataset\n",
    "<br>The Pornography-2k dataset is an extended version of the Pornography-800 dataset. The new dataset comprises nearly 140 hours of 1000 pornographic and 1000 non-pornographic videos, varying from\n",
    "six seconds to 33 min long. , the new Pornography-2k dataset is very assorted, including both professional and amateur content. Moreover, it depicts several genres of pornography, from cartoon to live action, with diverse behavior and ethnicity.\n",
    "\n",
    "<br> * TI-UNRAM pornographic image dataset\n",
    "<br>source - https://www.researchgate.net/publication/291001423_Pornographic_Image_Recognition_Based_on_Skin_Probability_and_Eigenporn_of_Skin_ROIs_Images\n",
    "\n",
    "Dataset | Total| Porn| Non-porn| Train/Test\n",
    "------|-------|----|-----|-----\n",
    "TI-UNRAM |  1,400| 685| 715| 700\n",
    "\n",
    "<br> * Kaggle's NSFW dataset \n",
    "<br> source - https://www.kaggle.com/drakedtrex/my-nsfw-dataset - 657MB data\n",
    "\n",
    "<br> * ImageNet\n",
    "<br> ImageNet is a visual Dataset that contains more than 15 million of labeled high-resolution images covering almost 22,000 categories. There are a little more than 21 thousand groups or classes (synsets), and a little more than 1 million images that have bounding box annotations (e.g. boxes around identified objects in the images).\n",
    "The photographs were annotated by humans using crowdsourcing platforms such as Amazon’s Mechanical Turk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
